# ğŸ™ï¸ Whisper Live - TranscripciÃ³n en Tiempo Real con Docker

Sistema de transcripciÃ³n automÃ¡tica en tiempo real usando OpenAI Whisper. El servidor corre en Docker y el cliente captura audio del micrÃ³fono de tu mÃ¡quina.

## ğŸ“‹ Requisitos

- **Docker** instalado ([Instalar Docker](https://docs.docker.com/get-docker/))
- **Python 3.8+** en el host (para el cliente)
- **MicrÃ³fono** funcional
- **8GB+ RAM** recomendado (4GB mÃ­nimo)

### Requisitos Opcionales

- **GPU NVIDIA** con CUDA (para mejor rendimiento)
- **nvidia-docker** si usas GPU

## ğŸš€ Inicio RÃ¡pido

### 1ï¸âƒ£ Construir y ejecutar el servidor

```bash
# OpciÃ³n A: Usar docker-compose (recomendado)
docker-compose up -d

# OpciÃ³n B: Usar docker directamente
docker build -t whisper-live-server .
docker run -d -p 9090:9090 --name whisper-server whisper-live-server
```

El servidor tardarÃ¡ unos segundos en iniciar y cargar el modelo.

### 2ï¸âƒ£ Instalar dependencias del cliente

#### En macOS (con entorno virtual):

```bash
# Instalar PortAudio (requerido para PyAudio)
brew install portaudio

# Crear entorno virtual
python3 -m venv venv-client

# Activar entorno virtual
source venv-client/bin/activate

# Instalar dependencias
pip install -r requirements-client.txt
```

#### En Linux/Windows:

```bash
# Linux: Instalar PortAudio del sistema
sudo apt-get install portaudio19-dev  # Debian/Ubuntu
# o
sudo dnf install portaudio-devel      # Fedora

# Windows: normalmente PyAudio viene pre-compilado, pero si falla:
# - Descargar wheel desde https://www.lfd.uci.edu/~gohlke/pythonlibs/#pyaudio

# Crear e instalar en entorno virtual
python -m venv venv-client
source venv-client/bin/activate  # Linux/Mac
# o
venv-client\Scripts\activate     # Windows

pip install -r requirements-client.txt
```

### 3ï¸âƒ£ Ejecutar el cliente

```bash
# Activar el entorno virtual si no estÃ¡ activado
source venv-client/bin/activate

# Ejecutar el cliente
python client.py
```

Â¡Habla al micrÃ³fono y verÃ¡s los subtÃ­tulos en tiempo real! ğŸ‰

## ğŸŒ Interfaz Web (Nueva)

Para una experiencia visual mÃ¡s completa, puedes usar la interfaz web:

### 1ï¸âƒ£ Iniciar el servidor (si no estÃ¡ iniciado)

```bash
docker-compose up -d
```

### 2ï¸âƒ£ Iniciar servidor web

```bash
cd web
python3 -m http.server 8000
```

### 3ï¸âƒ£ Abrir en el navegador

Navega a: **http://localhost:8000**

**CaracterÃ­sticas de la interfaz web:**
- âœ¨ DiseÃ±o moderno con dark mode
- ğŸ™ï¸ Captura de audio directamente desde el navegador
- ğŸ“Š VisualizaciÃ³n de nivel de audio en tiempo real
- ğŸŒ Selector de idioma y modelo
- ğŸ’¾ Descarga de transcripciones en formato SRT
- ğŸ“± DiseÃ±o responsive

Ver [web/README.md](file:///Users/dedece/dev/whisper_live_docker/web/README.md) para mÃ¡s detalles.

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Opciones del Cliente

```bash
# Usar un modelo diferente (mÃ¡s grande = mÃ¡s preciso pero mÃ¡s lento)
python client.py --model medium

# Conectar a un servidor remoto
python client.py --host 192.168.1.100 --port 9090

# Traducir al inglÃ©s en lugar de transcribir
python client.py --task translate --lang es

# Cambiar idioma de transcripciÃ³n
python client.py --lang es  # espaÃ±ol
python client.py --lang fr  # francÃ©s
```

**Modelos disponibles:**
- `tiny` - MÃ¡s rÃ¡pido, menos preciso
- `base` - Balance velocidad/precisiÃ³n
- `small` - Recomendado (default)
- `medium` - Mejor precisiÃ³n, mÃ¡s lento
- `large`, `large-v2`, `large-v3` - MÃ¡xima precisiÃ³n, requiere GPU

### Ver ayuda completa

```bash
python client.py --help
```

## ğŸ³ Comandos Docker Ãštiles

```bash
# Ver logs del servidor
docker logs whisper-server

# Detener el servidor
docker stop whisper-server

# Reiniciar el servidor
docker restart whisper-server

# Eliminar el contenedor
docker rm -f whisper-server

# Con docker-compose
docker-compose logs -f    # Ver logs
docker-compose down       # Detener y eliminar
docker-compose restart    # Reiniciar
```

## ğŸ® Uso con GPU

Para usar GPU NVIDIA y acelerar la transcripciÃ³n:

1. Instala [nvidia-docker](https://github.com/NVIDIA/nvidia-docker)

2. Edita `docker-compose.yml` y descomenta las lÃ­neas bajo `deploy`

3. Ejecuta:
```bash
docker-compose up -d
```

## ğŸ”§ SoluciÃ³n de Problemas

### El cliente no puede conectar al servidor

**Error:** `ConnectionRefusedError`

**SoluciÃ³n:**
1. Verifica que el servidor estÃ© ejecutÃ¡ndose:
   ```bash
   docker ps
   ```
2. Verifica que el puerto 9090 estÃ© mapeado:
   ```bash
   docker port whisper-server
   ```
3. Espera unos segundos mÃ¡s (el servidor tarda en cargar el modelo)

### No se captura audio del micrÃ³fono

**SoluciÃ³n:**
1. Verifica que tu micrÃ³fono estÃ© conectado y funcional
2. Otorga permisos de micrÃ³fono a la terminal (en macOS: Preferencias â†’ Seguridad â†’ MicrÃ³fono)
3. Prueba listar dispositivos de audio:
   ```python
   import sounddevice as sd
   print(sd.query_devices())
   ```

### TranscripciÃ³n muy lenta

**Soluciones:**
- Usa un modelo mÃ¡s pequeÃ±o: `python client.py --model tiny`
- Usa GPU si estÃ¡ disponible (ver secciÃ³n GPU)
- Cierra otras aplicaciones que consuman recursos

### El servidor se queda sin memoria

**SoluciÃ³n:**
- Usa un modelo mÃ¡s pequeÃ±o editando `docker-compose.yml`:
  ```yaml
  environment:
    - WHISPER_MODEL=tiny.en
  ```
- Aumenta la memoria disponible para Docker en configuraciÃ³n

## ğŸ“ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          WebSocket          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cliente   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€(puerto 9090)â”€â”€â”€â”€â”€â–ºâ”‚   Servidor   â”‚
â”‚  (Host)     â”‚                              â”‚   (Docker)   â”‚
â”‚             â”‚                              â”‚              â”‚
â”‚ - Captura   â”‚     EnvÃ­a audio chunks       â”‚ - Whisper    â”‚
â”‚   micrÃ³fono â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚   Model      â”‚
â”‚             â”‚                              â”‚              â”‚
â”‚ - Muestra   â”‚  â—„â”€â”€â”€â”€â”€â”€ SubtÃ­tulos â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ - Faster     â”‚
â”‚   subtÃ­tulosâ”‚                              â”‚   Whisper    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¤ Contribuir

Â¿Encontraste un problema o tienes una mejora? Â¡Las contribuciones son bienvenidas!

## ğŸ“„ Licencia

Este proyecto usa [Whisper Live](https://github.com/collabora/WhisperLive) y [OpenAI Whisper](https://github.com/openai/whisper).

## ğŸ™ CrÃ©ditos

- [OpenAI Whisper](https://github.com/openai/whisper) - Modelo de transcripciÃ³n
- [Whisper Live](https://github.com/collabora/WhisperLive) - Servidor/cliente en tiempo real
- [Faster Whisper](https://github.com/guillaumekln/faster-whisper) - Backend optimizado
